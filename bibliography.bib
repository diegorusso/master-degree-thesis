% Introduction
@misc{xu2020edge,
    title={Edge Intelligence: Architectures, Challenges, and Applications},
    author={Dianlei Xu and Tong Li and Yong Li and Xiang Su and Sasu Tarkoma and Tao Jiang and Jon Crowcroft and Pan Hui},
    year={2020},
    eprint={2003.12172},
    archivePrefix={arXiv},
    primaryClass={cs.NI}
}

@misc{tflite:intro,
    author    = "Renu Khandelwal",
    title     = "A Basic Introduction to TensorFlow Lite",
    url       = "https://towardsdatascience.com/a-basic-introduction-to-tensorflow-lite-59e480c57292"
}

@misc{tfmot:intro,
    author    = "Google",
    title     = "TensorFlow model optimization",
    url       = "https://www.tensorflow.org/model_optimization/guide"
}

@misc{tfmot:clustering_blog,
    author    = "Mohamed Nour Abouelseoud and Anton Kachatkou",
    title     = "Weight Clustering API",
    url       = "https://blog.tensorflow.org/2020/08/tensorflow-model-optimization-toolkit-weight-clustering-api.html"
}

@misc{han2015deep,
    title={Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
    author={Song Han and Huizi Mao and William J. Dally},
    year={2015},
    eprint={1510.00149},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{tfmot:clustering,
    author    = "Google",
    title     = "Weight Clustering",
    url       = "https://www.tensorflow.org/model_optimization/guide/clustering"
}

@misc{tfmot:quantization_blog,
    author    = "TensorFlow Model Optimization team",
    title     = "Quantization Aware Training with TensorFlow Model Optimization Toolkit - Performance with Accuracy",
    url       = "https://blog.tensorflow.org/2020/04/quantization-aware-training-with-tensorflow-model-optimization-toolkit.html"
}

@article{Jacob_2018,
   title={Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference},
   ISBN={9781538664209},
   url={http://dx.doi.org/10.1109/CVPR.2018.00286},
   DOI={10.1109/cvpr.2018.00286},
   journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
   publisher={IEEE},
   author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
   year={2018},
   month={Jun}
}

@misc{tfmot:quantization_training,
    author    = "Google",
    title     = "Quantization aware training",
    url       = "https://www.tensorflow.org/model_optimization/guide/quantization/training"
}

@misc{tfmot:quantization_post_training,
    author    = "Google",
    title     = "Post-training quantization",
    url       = "https://www.tensorflow.org/model_optimization/guide/quantization/post_training"
}

@misc{tfmot:pruning,
    author    = "Google",
    title     = "Trim insignificant weights",
    url       = "https://www.tensorflow.org/model_optimization/guide/pruning"
}

% Pruning
@inproceedings{lecun-90b,
 author = {LeCun, Yann and Denker, John and Solla, Sara},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Touretzky},
 pages = {598--605},
 publisher = {Morgan-Kaufmann},
 title = {Optimal Brain Damage},
 url = {https://proceedings.neurips.cc/paper/1989/file/6c9882bbac1c7093bd25041881277658-Paper.pdf},
 volume = {2},
 year = {1990}
}

@inproceedings{hassibi-93,
  author={B. {Hassibi} and D. G. {Stork} and G. J. {Wolff}},
  booktitle={IEEE International Conference on Neural Networks},
  title={Optimal Brain Surgeon and general network pruning},
  year={1993},
  volume={},
  number={},
  pages={293-299 vol.1},
  doi={10.1109/ICNN.1993.298572}
}

@misc{magnitude_pruning,
    author    = "Sayak Paul",
    title     = "Plunging Into Model Pruning in Deep Learning",
    url       = "https://wandb.ai/authors/pruning/reports/Plunging-Into-Model-Pruning-in-Deep-Learning--VmlldzoxMzcyMDg"
}

@misc{cnn,
    author    = "Wikipedia",
    title     = "Convolutional neural network",
    url       = "https://en.wikipedia.org/wiki/Convolutional_neural_network#Building_blocks"
}

@article{He_2017,
    title={Channel Pruning for Accelerating Very Deep Neural Networks},
    ISBN={9781538610329},
    url={http://dx.doi.org/10.1109/ICCV.2017.155},
    DOI={10.1109/iccv.2017.155},
    journal={2017 IEEE International Conference on Computer Vision (ICCV)},
    publisher={IEEE},
    author={He, Yihui and Zhang, Xiangyu and Sun, Jian},
    year={2017},
    month={Oct}
}

@article{Anwar_2017,
   title={Structured Pruning of Deep Convolutional Neural Networks},
   volume={13},
   ISSN={1550-4840},
   url={http://dx.doi.org/10.1145/3005348},
   DOI={10.1145/3005348},
   number={3},
   journal={ACM Journal on Emerging Technologies in Computing Systems},
   publisher={Association for Computing Machinery (ACM)},
   author={Anwar, Sajid and Hwang, Kyuyeon and Sung, Wonyong},
   year={2017},
   month={May},
   pages={1–18}
}

@misc{han2015learning,
    title={Learning both Weights and Connections for Efficient Neural Networks},
    author={Song Han and Jeff Pool and John Tran and William J. Dally},
    year={2015},
    eprint={1506.02626},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

@misc{liu2018rethinking,
    title={Rethinking the Value of Network Pruning},
    author={Zhuang Liu and Mingjie Sun and Tinghui Zhou and Gao Huang and Trevor Darrell},
    year={2018},
    eprint={1810.05270},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{Wang_2020,
   title={Pruning from Scratch},
   volume={34},
   ISSN={2159-5399},
   url={http://dx.doi.org/10.1609/AAAI.V34I07.6910},
   DOI={10.1609/aaai.v34i07.6910},
   number={07},
   journal={Proceedings of the AAAI Conference on Artificial Intelligence},
   publisher={Association for the Advancement of Artificial Intelligence (AAAI)},
   author={Wang, Yulong and Zhang, Xiaolu and Xie, Lingxi and Zhou, Jun and Su, Hang and Zhang, Bo and Hu, Xiaolin},
   year={2020},
   month={Apr},
   pages={12273–12280}
}
