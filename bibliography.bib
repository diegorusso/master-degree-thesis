% Introduction
@misc{xu2020edge,
    title={Edge Intelligence: Architectures, Challenges, and Applications},
    author={Dianlei Xu and Tong Li and Yong Li and Xiang Su and Sasu Tarkoma and Tao Jiang and Jon Crowcroft and Pan Hui},
    year={2020},
    eprint={2003.12172},
    archivePrefix={arXiv},
    primaryClass={cs.NI}
}

@misc{tflite:intro,
    author    = "Renu Khandelwal",
    title     = "A Basic Introduction to TensorFlow Lite",
    url       = "https://towardsdatascience.com/a-basic-introduction-to-tensorflow-lite-59e480c57292"
}

@misc{tfmot:intro,
    author    = "Google",
    title     = "TensorFlow model optimization",
    url       = "https://www.tensorflow.org/model_optimization/guide"
}

@misc{tfmot:clustering_blog,
    author    = "Mohamed Nour Abouelseoud and Anton Kachatkou",
    title     = "Weight Clustering API",
    url       = "https://blog.tensorflow.org/2020/08/tensorflow-model-optimization-toolkit-weight-clustering-api.html"
}

@misc{han2015deep,
    title={Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
    author={Song Han and Huizi Mao and William J. Dally},
    year={2015},
    eprint={1510.00149},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{tfmot:clustering,
    author    = "Google",
    title     = "Weight Clustering",
    url       = "https://www.tensorflow.org/model_optimization/guide/clustering"
}

@misc{tfmot:quantization_blog,
    author    = "TensorFlow Model Optimization team",
    title     = "Quantization Aware Training with TensorFlow Model Optimization Toolkit - Performance with Accuracy",
    url       = "https://blog.tensorflow.org/2020/04/quantization-aware-training-with-tensorflow-model-optimization-toolkit.html"
}

@article{Jacob_2018,
    title={Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference},
    ISBN={9781538664209},
    url={http://dx.doi.org/10.1109/CVPR.2018.00286},
    DOI={10.1109/cvpr.2018.00286},
    journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    publisher={IEEE},
    author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
    year={2018},
    month={Jun}
}

@misc{tfmot:quantization_training,
    author    = "Google",
    title     = "Quantization aware training",
    url       = "https://www.tensorflow.org/model_optimization/guide/quantization/training"
}

@misc{tfmot:quantization_post_training,
    author    = "Google",
    title     = "Post-training quantization",
    url       = "https://www.tensorflow.org/model_optimization/guide/quantization/post_training"
}

@misc{tfmot:pruning,
    author    = "Google",
    title     = "Trim insignificant weights",
    url       = "https://www.tensorflow.org/model_optimization/guide/pruning"
}

% Pruning
@inproceedings{lecun-90b,
    author = {LeCun, Yann and Denker, John and Solla, Sara},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {D. Touretzky},
    pages = {598--605},
    publisher = {Morgan-Kaufmann},
    title = {Optimal Brain Damage},
    url = {https://proceedings.neurips.cc/paper/1989/file/6c9882bbac1c7093bd25041881277658-Paper.pdf},
    volume = {2},
    year = {1990}
}

@inproceedings{hassibi-93,
    author={B. {Hassibi} and D. G. {Stork} and G. J. {Wolff}},
    booktitle={IEEE International Conference on Neural Networks},
    title={Optimal Brain Surgeon and general network pruning},
    year={1993},
    volume={},
    number={},
    pages={293-299 vol.1},
    doi={10.1109/ICNN.1993.298572}
}

@misc{magnitude_pruning,
    author    = "Sayak Paul",
    title     = "Plunging Into Model Pruning in Deep Learning",
    url       = "https://wandb.ai/authors/pruning/reports/Plunging-Into-Model-Pruning-in-Deep-Learning--VmlldzoxMzcyMDg"
}

@misc{cnn,
    author    = "Wikipedia",
    title     = "Convolutional neural network",
    url       = "https://en.wikipedia.org/wiki/Convolutional_neural_network#Building_blocks"
}

@article{He_2017,
    title={Channel Pruning for Accelerating Very Deep Neural Networks},
    ISBN={9781538610329},
    url={http://dx.doi.org/10.1109/ICCV.2017.155},
    DOI={10.1109/iccv.2017.155},
    journal={2017 IEEE International Conference on Computer Vision (ICCV)},
    publisher={IEEE},
    author={He, Yihui and Zhang, Xiangyu and Sun, Jian},
    year={2017},
    month={Oct}
}

@article{Anwar_2017,
    title={Structured Pruning of Deep Convolutional Neural Networks},
    volume={13},
    ISSN={1550-4840},
    url={http://dx.doi.org/10.1145/3005348},
    DOI={10.1145/3005348},
    number={3},
    journal={ACM Journal on Emerging Technologies in Computing Systems},
    publisher={Association for Computing Machinery (ACM)},
    author={Anwar, Sajid and Hwang, Kyuyeon and Sung, Wonyong},
    year={2017},
    month={May},
    pages={1–18}
}

@misc{han2015learning,
    title={Learning both Weights and Connections for Efficient Neural Networks},
    author={Song Han and Jeff Pool and John Tran and William J. Dally},
    year={2015},
    eprint={1506.02626},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

@misc{liu2018rethinking,
    title={Rethinking the Value of Network Pruning},
    author={Zhuang Liu and Mingjie Sun and Tinghui Zhou and Gao Huang and Trevor Darrell},
    year={2018},
    eprint={1810.05270},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{Wang_2020,
    title={Pruning from Scratch},
    volume={34},
    ISSN={2159-5399},
    url={http://dx.doi.org/10.1609/AAAI.V34I07.6910},
    DOI={10.1609/aaai.v34i07.6910},
    number={07},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    publisher={Association for the Advancement of Artificial Intelligence (AAAI)},
    author={Wang, Yulong and Zhang, Xiaolu and Xie, Lingxi and Zhou, Jun and Su, Hang and Zhang, Bo and Hu, Xiaolin},
    year={2020},
    month={Apr},
    pages={12273–12280}
}

@article{He_2018,
    title={AMC: AutoML for Model Compression and Acceleration on Mobile Devices},
    ISBN={9783030012342},
    ISSN={1611-3349},
    url={http://dx.doi.org/10.1007/978-3-030-01234-2_48},
    DOI={10.1007/978-3-030-01234-2_48},
    journal={Lecture Notes in Computer Science},
    publisher={Springer International Publishing},
    author={He, Yihui and Lin, Ji and Liu, Zhijian and Wang, Hanrui and Li, Li-Jia and Han, Song},
    year={2018},
    pages={815–832}
}

@misc{heuristic,
    author    = "Wikipedia",
    title     = "Heuristic",
    url       = "https://en.wikipedia.org/wiki/Heuristic"
}

@misc{howard2017mobilenets,
    title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
    author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
    year={2017},
    eprint={1704.04861},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{review_mobilenet,
    author    = "Arun Mohan",
    title     = "Review On MobileNet v1",
    url       = "https://medium.com/datadriveninvestor/review-on-mobilenet-v1-abec7888f438"
}

@misc{cifar_10,
    title= {CIFAR-10 (Canadian Institute for Advanced Research)},
    author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
    url= {http://www.cs.toronto.edu/~kriz/cifar.html},
}

@inproceedings{imagenet_cvpr09,
    author = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
    title = {{ImageNet: A Large-Scale Hierarchical Image Database}},
    booktitle = {CVPR09},
    year = {2009},
    bibsource = "http://www.image-net.org/papers/imagenet_cvpr09.bib"
}

@misc{vela_compiler,
    author    = "Arm Ltd.",
    title     = "The Vela compiler",
    url       = "https://developer.arm.com/documentation/101888/0500/NPU-software-overview/NPU-software-tooling/The-Vela-compiler?lang=en"
}

@incollection{rigl,
 author = {Evci, Utku and Gale, Trevor and Menick, Jacob and Castro, Pablo Samuel and Elsen, Erich},
 booktitle = {Proceedings of Machine Learning and Systems 2020},
 pages = {471--481},
 title = {Rigging the Lottery: Making All Tickets Winners},
 year = {2020}
}
